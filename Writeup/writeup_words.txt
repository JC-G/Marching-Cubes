\section*{Abstract}
This project explores a method for procedurally generating terrain by applying a variation of Marching Cubes known as Transvoxel. We use an octree data structure to break down a large world into chunks at varying levels of detail, and apply parallel processing on the GPU to rapidly generate geometry on a per-chunk basis. We explore applications of this approach, modifying geometry in real-time by making localized changes to the underlying distance function. Finally, we use the generated meshes with a well-known physics library, and apply procedural shading.

\section{Introduction}

Marching Cubes is an algorithm for polygonising a scalar field. Designed by William E. Lorensen and Harvey E. Cline in 1987\cite{10.1145/37402.37422}, the original application was in medical imaging, to create anatomical models using data from 3D scans such as CT scans. When it was written, the algorithm was comparatively expensive to execute, due to the limited hardware available. 
 
Procedural terrain generation is a popular technique within the video game industry, allowing for large areas of geometry to be created, according to mathematical rules, rather than the traditional method of 3D modelling, which is time-consuming for the modeller, and takes up a large amount of storage space.

The increase in processing power available, as well as the parallel design of the GPU, means that it is achievable to use Marching Cubes to generate large amounts of geometry at an interactive framerate. When combined with a level-of-detail system, it is possible to render very large regions of terrain, that can be interacted with and modified in real time.

\section{Background}
\subsection{Signed Distance Functions}

To pass a scalar field to the Marching Cubes algorithm, we will use a signed distance function (SDF). This is a function of the form $f:\mathbb{R}^3 \rightarrow \mathbb{R}$. The shape represented by an SDF is the implicit surface $f\left(x,y,z\right) = 0$. An SDF should have the following properties:

If $\left(x,y,z\right)$ is inside the surface, $f\left(x,y,z\right) < 0$. If $\left(x,y,z\right)$ is outside the surface, $f\left(x,y,z\right) > 0$. This is the defining property of an SDF, without which Marching Cubes will not produce valid geometry.

$f\left(x,y,z\right)$ represents the smallest (signed) euclidean distance from the point $\left(x,y,z\right)$ to the surface. Many functions we are using do not give the exact distance, however for best results the value should be a good approximation, and for floating point precision reasons, must be at least the same order of magnitude. This property is used to interpolate the positions of vertices, and as such the accuracy of the distance approximation impacts the accuracy of the generated surface. An SDF such that $f\left(x,y,z\right)$ gives the correct distance everywhere is an \textit{exact} SDF. Otherwise, it is an \textit{approximate} SDF.

Near the surface, $f$ is continuous, and has all first partial derivatives. This is useful since the gradient of an SDF on the surface gives the normal vector to the surface at that point.


An article by Inigo Quilez lists some useful SDFs~\cite{quilez:sdf}. Figures \ref{fig:Circle_SDF} and \ref{fig:Hill_SDF} show some examples.

2 dimensional exact SDF representing a circle. The SDF shown is $f\left(x,y\right)=\sqrt{x^2+y^2}-1$, with the area where $f\left(x,y\right)<0$ shaded. Also shown are the contours where $f\left(x,y\right)=0.1,0.2,...0.5$. At the center point $\left(0,0\right)$, the gradient is undefined. However, since this point is not close to the surface, $f$ can still be used as an SDF without issue.


2 dimensional approximate SDF for the curved surface defined by $f\left(x,y\right)=y-\left(1-\frac{x^2}{3}\right)$. The contour lines are no longer uniformly spaced, as they would be with an exact SDF.

Many shapes have an exact SDF that is complex to evaluate, so it is more efficient to use an approximate SDF instead. We will see an example of this in section \ref{example_brushes}.

The set-theoretical operations of union, intersection, and difference have representations using the $\min$ and $\max$ functions. Where the function $\min\left(f,g\right)$ is not differentiable at the point where $f = g$, we choose the derivative of either $f$ or $g$. Using these functions, it is possible to combine SDFs of many shapes to produce a surface that is more complex.

\subsection{Noise}
Use of noise to create natural-looking heightmaps is a commonly used technique. A noise function assigns a pseudorandom value in the range $\left[0,1\right]$ to each point in $\mathbb{R}^n$. We will consider coherent noise, which has the property that input values that are far apart will produce random-looking outputs, but input values that are close together will result in similar output. This means that the function is smooth. One such function is value noise, which assigns a pseudorandom value to each grid point, and then smoothly interpolates between these values to assign a value to every point. Multiple layers or \textit{octaves} of value noise at different scales can be added together to produce fractal noise. More advanced noise algorithms exist, such as Perlin or Simplex noise\cite{PerlinChapter2N}, that show fewer regularities. Figures \ref{fig:value_noise} and \ref{fig:better_noise} show some example noise functions.

Left: A single layer of value noise. Right: 8 octaves of value noise.

Left: Perlin Noise. Images generated using functions \texttt{cnoise} and \texttt{snoise} respectively, from the cited collection of reference implementations\cite{github_2014}.}

The output of a noise function can be scaled to define a convincing heightmap, typically giving a function $y = h\left(x,z\right)$ defining the height of the terrain at a given $\left(x,z\right)$ coordinate. We will extend this to an approximate SDF, using the formula $f\left(x,y,z\right) = y - h\left(x,z\right)$. In this case, the distance approximation worsens as the steepness of the slope of $h\left(x,z\right)$ increases.

It is also possible to use a 3D noise function in an SDF, for example in generating features such as caves. By defining a value at which the surface will be, for example $0.5$, we can use the SDF $f\left(x,y,z\right) = \mathrm{noise}\left(x,y,z\right) - 0.5$ to represent a shape such that only points with noise values greater than 0.5 are outside of the shape. With careful choices of parameters, this creates empty pockets throughout the shape. We will use this type of SDF for benchmarking purposes, since it generates a relatively large amount of geometry, and represents a shape that cannot be created using a heightmap approach. 

\subsection{Marching Cubes Algorithm}

Marching Cubes is an algorithm for polygonising a 3 dimensional scalar field. It works by splitting the space into a uniform grid of cubes (\textit{cells}), and sampling the scalar field at each cell vertex. When the sign of the SDF changes on adjacent cell vertices, these sample values are linearly interpolated along the edge, and a vertex is placed where the value of this linear interpolation is 0, approximating the position where the cell edge intersects the surface. This is shown in figure \ref{fig:linear_interpolation}. Pre-computed lookup tables, such as those to be discussed in section \ref{section:lookup_tables}, determine the triangulation between these vertices in each cell. Figure \ref{fig:ms_example} illustrates the Marching Cubes algorithm.

2D demonstration of linear interpolation. These cells contain the same class of geometry, but with different SDF values, and hence different vertex positions. The red lines show the generated geometry.

2D example of Marching Cubes approximating a circle.

\subsubsection{Limitations of Marching Cubes}
Marching Cubes was chosen for this project because the geometry for each grid cell can be generated independently from other cells. It produces a relatively accurate result for smooth shapes. However, it is not the best choice of algorithm for shapes with sharp corners, such as the shape in figure \ref{fig:sharp_corner}.

Inaccuracies near the sharp edge of this cylinder are visible.


For this purpose, an algorithm such as Dual Contouring\cite{10.1145/566654.566586} may produce better results. However, this algorithm generates triangles that span multiple grid cells, so it cannot be parallelised with the same method.

\subsection{GPU Programming}
A GPU is designed for applications where a similar calculation is performed many times on varying data. Traditionally, this covers uses such as vertex shaders, which determine the position of every vertex in a 3D scene, or fragment shaders, which determine the color of every pixel on a screen. A modern GPU is capable of performing millions of individual shader invocations per frame. We use the OpenGL API, and the C-style GLSL shader language that comes with it, to write code for the GPU.

We make use of compute shaders, which are not part of the graphics rendering pipeline, but are called by the OpenGL API and take advantage of the parallel architecture of the GPU. When a compute shader is executed, many invocations of the same code are executed in parallel, through the API function \texttt{glDispatchCompute}. These are indexed by the built-in GLSL variable \texttt{gl\_GlobalInvocationID}, a 3-component integer vector, that is different for each invocation. For example, a shader designed to calculate $f\left(x,y,z\right)$, for $ \left(x,y,z\right)$ ranging over integer-valued triples in $\left[0,32\right]^3$ would need to be configured so that \texttt{gl\_GlobalInvocationID} varies over all of the triples in this range.

To display geometry, and to interact with OpenGL, we make use of some open source libraries, namely GLFW\cite{glfw}, for creating a window and handling input, GLEW\cite{glew}, to load the OpenGL API functions, and GLM\cite{g-truc_2005}, to provide mathematical functions such as manipulation of vectors, in C++.

\section{Algorithm Design}

\subsection{LOD System}
Even with an efficient GPU-based implementation, it becomes infeasible to generate and render a large uniform grid of Marching Cubes chunks. Generating large amounts of triangles far from the camera is unnecessary, since the detail will not be visible. For this reason, it is necessary to have a dynamic level of detail (LOD) system.

\subsubsection{Octree}

To implement a versatile LOD system, an octree data structure is used. Each octree node represents a cuboid of space, such that the root node of the octree represents the entire renderable world, and the 8 children of an octree node equally divide the space represented by the parent node into octants. 

A \textit{chunk} refers to one of these regions of space, and consists of $n_x \cdot n_y \cdot n_z$ grid cells. The scale of these grid cells is determined by the depth of the octree node, with each level in the octree corresponding to a halving of the scale of a grid cell in each dimension. Geometry is generated at each leaf node, so the depth of the leaf node corresponds to the scale of the grid used within the generation algorithm, and hence the level of detail at which the geometry is generated. We will usually use chunks of size $32^3$, although other sizes are useful for demonstration purposes.

Using an octree, any condition can be used to determine the level of detail at any given point. We will use this in section \ref{section:physics_meshes} to control the level of detail around physics objects, for consistent collision detection. The level of detail is controlled with the functions \texttt{shouldSplit}, which returns whether a leaf node should split into its 8 children, and \texttt{shouldChop}, which returns whether a non-leaf node should become a leaf. When the octree changes, geometry associated with octree leaves that became branches, or were removed from the octree, is deleted, and new geometry is generated at each new leaf.

\caption{A plane generated using Marching Cubes, within this octree LOD system. Here, the chunk size is $4^3$. The level of detail is configured to decrease as the distance from the camera increases.}

\subsection{The Transvoxel Algorithm}

Using Marching Cubes with multiple different grid cell sizes causes cracks on the boundary between chunks at different scales, since the vertices generated at different grid scales do not always line up with each other. Figure \ref{fig:cracks_demo} illustrates this, and figure \ref{fig:cracks2} shows the problem within my implementation.

This figure shows the faces of 2 adjacent grid cells. The exact surface represented by the SDF is shaded in purple. The dotted lines show the edges produced by Marching Cubes at the level of detail of these grid cells, and the level below. When these cases occur next to each other, the red space in between the dotted lines forms a crack in the geometry.

Cracks between different levels of detail cause the blue background to be visible between chunks.

The Transvoxel algorithm\cite{lengyel_2010} is an algorithm based on Marching Cubes that solves this problem by adding additional vertices along cell edges that are adjacent to higher resolution grid cells.

This is done by splitting a cell at the lower resolution (a half-resolution cell) into a regular cell and some amount of transition cells, so that transition cells border the regular cells at the higher resolution (full-resolution cells). These transition cells serve as a method of stitching the gap in between half-resolution and full-resolution cells.

Illustration of 2 possible configurations of transition cells on the boundary between levels of detail. The half-resolution regular cell has been resized, and transition cells fit in the space made in between the cells. Reproduced from figure 4.9 in the Transvoxel algorithm paper\cite{lengyel_2010}.

Like Marching Cubes, the original Transvoxel implementation was written for a standard CPU. It works similarly to Marching Cubes, relying on large lookup tables, and can be implemented to work independently on grid cells, so it is possible to take advantage of the parallel processing power of the GPU. We will modify a set of lookup tables provided by the original author of the Transvoxel algorithm\cite{lengyel_2009}. A graphic showing all of the possible triangulations in the Transvoxel algorithm is available from the same source\cite{lengyel}.

\subsubsection{Lookup Tables}

This section demonstrates the Transvoxel lookup tables. These tables have been flattened from multidimensional arrays, since they will be passed to shaders as buffers. Vertex indexing data that would allow for reuse of vertices has been removed, for the reason described in section \ref{section:downsides}.

\paragraph{Regular cell lookup tables}
Regular cells have 8 cell vertices, each of which has a distinct SDF sample value. Figure \ref{fig:tv_labels} shows the vertex naming conventions for regular cells.

Regular cell vertex naming convention. Reproduced from figure 3.7 of the Transvoxel paper~\cite{lengyel_2010}.

Calculation of \texttt{cellIndex}, and lookup tables, for regular cells. An example of their usage is given below.


The array \texttt{gridCells} contains the SDF sample values, and \texttt{cellIndex} is an index into the subsequent tables, calculated based on these values. 
\texttt{regularCellClass} maps the 256 possible values of \texttt{cellIndex} to one of 16\footnote{There are more classes of cell than there are values in \texttt{regularCellClass} and \texttt{transitionCellClass}, because the tables combine the classes that use the same triangulation with different vertices.} cell classes, which defines the triangulation used within the cell.
\texttt{regularCellData} contains a row of 16 numbers for each of the 16 cell classes. Each row starts with a value that encodes the number of distinct vertices and triangles in the triangulation, which is unused in my implementation. The following 15 entries are indices into \texttt{regularVertexData}, storing the order in which the vertices in the cell triangulation will be used. 
\texttt{regularVertexData} contains a row of 12 numbers for each \texttt{cellIndex}. Each number encodes an edge of the grid cell using 2 vertex indices, as in figure \ref{fig:tv_labels}. 
Finally, \texttt{regularTotalTable} contains the number of vertices in the triangulation for each class, including duplicates. This acts as a replacement for the unused triangle count in \texttt{regularCellData}.
As an example, consider the case where only vertex 0 is inside the terrain, giving a binary \texttt{cellIndex} of $00000001$. This will generate geometry like figure \ref{fig:regular_cell_example_case}. The cell class, from \texttt{regularCellClass}, is \texttt{0x01}. The number of vertices to be generated, from \texttt{regularTotalTable}, is 3. The vertex indices to be used, from \texttt{regularCellData}, are 0, 1, and 2. The vertex positions, from \texttt{regularVertexData}, are \texttt{0x01, 0x02, 0x04}. Hence a triangle will be generated with a vertex on the edge between grid cell vertices 0 and 1, a vertex on the edge between grid cell vertices 0 and 2, and a vertex on the edge between grid cell vertices 0 and 4, in that order.

A regular cell of the same class as the example, reproduced from the diagram of all Transvoxel cell classes\cite{lengyel}. Note however that this cell is not oriented the same as figure \ref{fig:tv_labels}.

\subsubsection{Transition cell lookup tables}

A transition cell uses 9 distinct SDF sample values, at vertices 0 through 8 in figure \ref{fig:tv_transition_labels}. Cell vertices 9, A, B, and C take their sample values from the vertices directly opposite them: vertices 0, 2, 6, and 8 respectively. Thus there are 512 possible cases to consider. Figure \ref{fig:tv_transition_cellIndex} shows how cell vertices are considered, for the purpose of calculating \texttt{transitionCellIndex}, as implemented in listing \ref{tv_transition_tables}.

Hexadecimal vertex naming convention for transition cells. (a) shows the higher resolution face of the cell, and (b) shows the opposite, lower resolution face. Reproduced from figure 4.16 of the Transvoxel paper\cite{lengyel_2010}

Hexadecimal contribution to \texttt{transitionCellIndex} by each cell vertex on the higher resolution face of a transition cell. Reproduced from figure 4.17 of the Transvoxel paper\cite{lengyel_2010}

Calculation of \texttt{transitionCellIndex}, and lookup tables for transition cells. An example of their usage is given below.


The tables perform the same roles as their regular cell counterparts, with \texttt{transitionCellClass} mapping \texttt{transitionCellIndex} to one of 56 classes. The eighth bit in \texttt{transitionCellClass} corresponds to a triangulation where the triangles face in the opposite direction, so a value of \texttt{0x87} in \texttt{transitionCellClass} corresponds to cell class \texttt{0x07}, with the triangles facing in the opposite direction. 

For example, consider the transition cell where vertex 0 is inside the terrain. Then vertex 9 will also be considered as inside. This will generate geometry like figure \ref{fig:transition_cell_example_case}. \texttt{transitionCellIndex} will be calculated as $000000001$, and the tables will be used in the same way as their regular counterparts. 

In this case, we find that there is a triangle using vertex indices 0, 1, and 3, and another using indices 1, 2, and 3. Vertex 0 is between cell vertices 0 and 1, vertex 1 is between cell vertices 0 and 3, and so on.

A transition cell of the same class as the example, reproduced from the diagram of all Transvoxel cell classes\cite{lengyel}.

\subsubsection{Adaptation of the algorithm to GPU}

We now describe a Transvoxel implementation on the GPU, making use of these modified lookup tables. The algorithm is implemented in 3 separate compute shader phases, executed in order, to generate the geometry for a single chunk.

The chunk faces where transition cells should be generated are encoded in the variable \texttt{edgeIndex}, which is discussed in section \ref{section:edgeIndex}.

\underline{Distance function computation}: For each grid cell vertex, the SDF is sampled, and stored in a buffer. For vertices on the face of the chunk, the SDF is sampled at additional points on the face, for use in transition cells. This shader is invoked once for each grid cell vertex, and the invocations corresponding to the vertices on the faces where transition cells are generated are responsible for calculating the additional sample points. This is done separately to the following stages to avoid recomputation of the SDF, since one cell vertex may belong to up to 8 neighboring cells. Figure \ref{fig:tv_gen_grid} shows the points to be sampled on the face of a 2x2x2 chunk for various invocations.


The 4 blue points in the bottom left are those that will be sampled by an invocation on the vertex at $\left(0,0\right)$, the 2 green points in the bottom right will be sampled by an invocation on the vertex at $\left(2,0\right)$, and the singular purple point will be sampled by an invocation on the vertex at $\left(2,2\right)$.

\underline{Counting phase}: For each regular cell, calculate the number of mesh triangles within it, and if this number is non-zero (the cell is not all air, or all solid), add it to the list of cells to generate geometry for in the next phase.

Code for counting the number of vertices and marchable grid cells in the chunk. \texttt{cellIndex} is calculated according to listing \ref{tv_transition_tables}, using the SDF values from the previous stage.

The same process is followed for transition cells, which are appended to the same buffer, separately from the regular cells they are adjacent to. The orientation of the transition cell is also stored in the buffer.



\underline{Polygonisation phase}: For each cell passed by the previous phase through the buffer \texttt{marchableList}, the geometry is created, and the vertices of the geometry are linearly interpolated as described in section \ref{section:mc}. 

 Code for generating the geometry in a regular cell.
 
When a regular cell has been made smaller to accommodate transition cells, the SDF has been sampled at the grid cell vertices, rather than the vertices of the regular cell. This introduces inaccuracies in the resulting geometry. The Transvoxel paper~\cite{lengyel_2010} describes a transformation that solves this issue by moving vertices on the lower resolution face of the transition cell, and the corresponding vertex on the neighboring regular cell, so they are on the edge that the regular cell would have generated. This was implemented in listing \ref{tv_poly_regular}.

Transition cells are handled separately from regular cells, even if they share the same grid cell. There are multiple possible shapes a transition cell may need to take, some of which were shown in figure \ref{fig:transition_cells}, and this is calculated based on \texttt{edgeIndex}. Since the presence of a transition cell means that a regular cell has been resized, the above transformation is performed for all geometry generated on the lower resolution face of the transition cell. Otherwise, the actual code used to determine the geometry is similar, using the lookup tables from listing \ref{tv_transition_tables}.

There is a case where multiple vertices of a transition cell may be moved to the same place, resulting in zero-width triangles being generated, which could interfere with other algorithms the generated geometry is used with. However, the number of zero-width triangles is small, and it turns out that in the applications considered in this report, zero-width triangles have not caused any issues.


A plane generated with the Transvoxel algorithm. The circled transition cell has vertices placed on top of each other, leading to zero-width triangles.

\subsubsection{Calculation of edgeIndex}

The variable \texttt{edgeIndex} is a 6-bit integer, with each bit storing whether a face of a chunk should have transition cells. For each octree leaf containing geometry, the octree is searched using a recursive algorithm, to find neighboring nodes in each direction at the same depth. If a neighbor is a leaf, then the neighboring geometry is at the same level of detail. If no neighbor exists at the same depth in some direction, then the neighboring geometry is at a lower level of detail. \texttt{edgeIndex} is not modified in this case, since it will be modified for the lower level of detail geometry. If the neighbor is not a leaf, then the neighboring geometry is at a higher level of detail, and \texttt{edgeIndex} is modified to record that transition cells should be generated in that direction. Figure \ref{fig:octree_neighbors} shows some example cases.

The blue cell has 3 neighbors at the same level of detail. The green neighbor is within the same parent octree cell, and no recursive calls are needed. The red neighbor is not within the same parent cell, so the neighbor of the parent is found, and the corresponding child of this neighbor is returned. The orange neighbor is not a leaf, so \texttt{edgeIndex} is updated to reflect this. There is no neighbor at the same level of detail above the blue cell.

Code for finding the neighbor of a node at the same level of detail in an octree. The children of a node are stored as a 3D array of pointers: \texttt{Octree* myChildren[2][2][2];}. \texttt{relativePosition} is a 3-component vector, where exactly one component is non-zero, corresponding to the direction in which to look for the neighbor. For example, a value of $\left(1,0,0\right)$ searches in the positive X direction.

\subsubsection{Downsides of parallelisation}

This method of parallelisation presents some downsides. Triangles are placed into the vertex buffer as parallel invocations of the third compute shader increment the atomic counter, which may be different between calls. This means that there is no way to reliably use an index buffer for vertices, which would be beneficial since multiple vertices are often generated in the same place, resulting in many duplicates in the vertex array. This is why vertex indexing data was removed from the Transvoxel tables. Nevertheless, this is a worthwhile tradeoff, with the GPU implementation greatly outperforming the CPU implementation, as demonstrated in section \ref{section:GPUCPUcomparison}.

\subsubsection{Algorithm speed comparison}

In this section, we evaluate the performance of the above Transvoxel implementation, comparing to a CPU implementation of Marching Cubes based on one by Paul Bourke\cite{bourke_1994}. We also include an implementation of the same Marching Cubes algorithm, parallelised using the same 3-phase technique.

The SDF used for these comparison tests is a scaled 3D fractal noise function, as described in section \ref{section:noise}. An effort has been made to ensure the SDF is the same on the CPU and GPU, however due to floating point inaccuracies and differences between the GLSL and C++ implementations, the SDF occasionally produces slightly different values between implementations, and this results in the number of triangles generated being different. However, this difference is small compared to the total number of triangles generated, so is unlikely to have an impact on the runtime comparison.

Table \ref{tab:comparison-time} shows the time taken to generate different numbers of chunks of 3D noise, of size $32^3$, using each of the implementations described. When using the Transvoxel algorithm, transition cells have been generated on the +x, +y, and +z faces. This means that the number of triangles generated is also higher for the Transvoxel algorithm. Table \ref{tab:comparison-tris} shows the number of triangles generated in each experiment. All experiments were run using an Intel i9-9900k and Nvidia RTX 2080ti. Each experiment was run 5 times, and the average time is shown.

Performance comparison between the 3 implementations.

Difference in number of triangles generated between the 3 implementations. The number of triangles in the 1 chunk test is the same, even for the Transvoxel test, because no geometry is generated on the edge of the chunk.

A wireframe of the 10x1x10 chunk test.

\subsubsection{Octree Refinement}

The Transvoxel algorithm is sufficient in most cases for eliminating cracks in the geometry. However, there are octree configurations which could occur, where different levels of detail appear next to each other, even once transition cells have been generated. Figure \ref{fig:octree_neighbor_error} shows an example of this.

An illustration of where different levels of detail may occur next to each other. Areas where transition cells are generated are shaded in blue. The area where transition cells are generated, but different levels of detail will still be adjacent to each other, is shaded in red.

A refinement strategy is used to ensure that cases like this do not occur within the octree. When the octree needs to be modified, the following 4 steps are performed in order:

Traverse the octree, visiting every node. If a non-leaf node satisfies \texttt{shouldChop}, then flag it, but do not delete its children yet. If a leaf node satisfies \texttt{shouldSplit}, then split it, creating 8 new leaf nodes. The newly created leaves will also be traversed in this step, allowing more than one layer of the octree to be generated at once.

The first stage in the octree refinement process.

If the first step changed the structure of the octree, or flagged any nodes, check whether any nodes have neighbors which are more than one level of detail higher, using the \texttt{getNeighbor} function described in listing \ref{octree_neighbor}. If this occurs on a leaf node, then split the node into its 8 children, otherwise unflag it, if it was flagged. This flagging prevents octree nodes and the corresponding geometry from being deleted in the first step, then immediately recreated in the subsequent steps. Performing this step may create inconsistencies elsewhere, so it is performed repeatedly, until no more changes are made.

The second stage in the octree refinement process. \texttt{edgeNeighbors} gives the relative positions of the 6 neighboring nodes at the same level, and \texttt{childPosition} gives the position of the child to check in each neighbor. The flow of this code is designed such that exactly the 4 children of the neighboring node that touch the chunk in this node are checked.

Once the previous step is complete, delete the children of any nodes which are still flagged.

The third stage in the octree refinement process.

Generate geometry for all new leaves, and all leaves that needed regeneration, for example if the geometry inside them has changed. Also regenerate geometry for leaves where \texttt{edgeIndex} has changed, so that cracks do not appear after changing the level of detail of a neighboring chunk.

The fourth stage in the octree refinement process.


\section{Terrain Modification}
\subsection{Method of Terrain Modification}
Since the parallel Transvoxel algorithm runs so efficiently, it is possible to regenerate significant portions of geometry in between frames, and so real-time terrain editing is achievable. 

We will proceed by adding primitive shapes to the SDF itself, using the set operations discussed in section \ref{section:sdf}. This means that the shape represented by the SDF changes, so the generated geometry also changes, regardless of the level of detail it is generated at. It also means that no subsequent transformations have to be performed on the geometry, after the Transvoxel algorithm has generated it.

\subsection{Adding Primitives to the SDF}

To implement terrain modification, the \texttt{Brush} interface is used. Each \texttt{Brush} object contains information about a shape that has been added to the world, and has 2 methods which are overridden for each type of shape. The first method is \texttt{getBoundingBox()}, which returns an axis-aligned bounding box such that the shape lies entirely within the box. The second is \texttt{getBrushParams()}, which returns a \texttt{BrushParams} object containing all of the parameters required to add this shape to the SDF. For example, it may contain the radius of a sphere, or the control points and thickness of a shape defined by a Bezier spline. It always contains the values \texttt{bottom} and \texttt{top}, which correspond to diagonally opposite corners of the bounding box, \texttt{type}, a constant denoting the type of shape, and \texttt{mode}, a constant describing whether the shape should be added or subtracted from the SDF.

A new \texttt{Brush} object is created each time a shape is added to the world. Each \texttt{Octree} node stores a list of pointers to the \texttt{Brush} objects that are inside the region the node represents. 


Code to add a new brush into the octree. The brush is added recursively to lists at all levels, so each leaf has a list of exactly the brushes that are partially inside it. The flag \texttt{needsRegen} indicates that the geometry within the chunk has changed.}]


When the octree is modified, it is necessary to update the lists of the newly created nodes. To do this, the \texttt{split()} function is modified to update the brush lists of each child.

Snippet from \texttt{split}, showing how brushes are added to child nodes, when they are created.

Each brush type has an SDF and normal function implementation in GLSL. When geometry is generated, the \texttt{BrushParams} objects corresponding to the brushes in the chunk are passed to the generation algorithm, and they modify the SDF via set union or subtraction. The normal function is computed by taking the shape which produces the smallest value of the SDF, and returning the normal function for that shape. Both the SDF and normal suffer from inaccuracies when a non-exact SDF is very far from the actual distance value, and in extreme cases, the resulting inaccurate interpolation can lead to cracks appearing in the geometry. Figure \ref{fig:inaccurate_sdf} shows an example of an SDF that exhibits this problem. However, with careful choices of SDF, in most cases it produces an acceptable result.


An example of an inaccurate sphere SDF on an accurate plane SDF. Here the value of the SDF has been scaled to be much smaller than it should be. The incorrect SDF has been chosen for interpolation, resulting in the blocky appearance of the sphere, and cracks on the further away sphere, where the level of detail changes. This also results in the incorrect normal being used, as shown by the dark patches underneath the spheres.

  
For efficiency reasons, an SDF is only considered when the grid cell being worked on lies within its bounding box, preventing evaluation of SDFs that will not affect the geometry within the cell. This introduces discontinuities in the overall SDF, and for this reason, it is necessary to enforce that the bounding box always contains the grid cells containing geometry generated for the brush.

\subsection{Interactive Terrain Modification}
User interaction with the terrain modification system uses a set of pre-defined actions, defined through classes derived from a base \texttt{Action} class, shown in listing \ref{action_methods}.

Methods of the \texttt{Action} class responsible for handling user interaction.

These functions are designed to be overridden, to implement the corresponding functionality. The argument to the first 3 is the position at which the mouse is pointing. The method \texttt{onCancel} is called when the action has been cancelled, to clean up any state that has been created, for example in an action that stores intermediate control points. The methods \texttt{increaseSize} and \texttt{decreaseSize} provide a standard way of increasing and decreasing the size of a shape, for example changing the radius of a sphere, or thickness of a spline curve. The final method, \texttt{handleInput}, allows more general input for an action, which is useful for actions that require more input than the options given in the other functions. It has a default implementation, which calls the other functions.

Default implementation of \texttt{handleInput}.

The generic \texttt{Brush} and \texttt{Action} interfaces makes it quick to implement new shapes, since the interfaces need only be filled out. The complex addition is the definition of the SDF and normal function, which is different for every shape.

\subsubsection{Raycasting}

To determine where a brush should be placed, we perform a raycast from the camera in the look direction. We take advantage of the octree to do this efficiently, considering only leaf nodes where the ray passes through their bounding box. For each of these nodes, we perform ray-triangle intersection tests to determine the closest point of intersection to the camera, using a library function. Since the geometry data is generated on the GPU, it first needs to be copied to the CPU.

Snippet from the procedure \texttt{mapGeometry} to copy geometry data for a chunk from the GPU to the array \texttt{mappedTriangles}. \texttt{isMapped} is an atomic boolean storing whether \texttt{mapGeometry} has already been called for this chunk.


It is possible to perform ray-triangle intersection tests within an OpenGL compute shader, removing the need for geometry data to be copied to the CPU. However, this copying will need to be done for physics simulation anyway, and is only done once per chunk of geometry, so this method is sufficient.

\subsubsection{Example Brush Implementations}
Any shape for which an SDF and normal function can be derived may be implemented as a brush, using the method described in section \ref{section:modification_implementation}. In section \ref{section:sdf} we gave a useful resource for SDF implementations~\cite{quilez:sdf}.
It is also necessary to provide a normal function for each SDF. In some cases, the partial derivatives can be computed exactly, particularly when the SDF has a simple form. For example, the SDF of a sphere with radius 1, centered at the origin, is $f\left(x,y,z\right) = \sqrt{x^2+y^2+z^2}-1$. The gradient vector at point $\left(x,y,z\right)$ is $\nabla f = \left(\frac{x}{\sqrt{x^2+y^2+z^2}},\frac{y}{\sqrt{x^2+y^2+z^2}},\frac{z}{\sqrt{x^2+y^2+z^2}}\right)$. In this case, the gradient happens to already have length 1, but if it is not, it should be normalised with the GLSL \texttt{normalize} function. 
The normal can also be approximated, but this can be computationally expensive, because it requires multiple evaluations of the SDF.

Approximation of the normal of an SDF, using the method of finite differences.


\paragraph{Example Shape: Ellipsoid}
Another article by Inigo Quilez~\cite{quilez:ellipsoid} lists various approximate SDFs for ellipsoids. Listing \ref{ellipsoid_sdf} shows my transformation of the first SDF listed in this article into an SDF representing an ellipsoid centered at an arbitrary point, as well as a normal function, which has been derived by computing the gradient of this SDF.

Approximate SDF and normal function for an ellipsoid.

Figure \ref{fig:editing_ellipsoids} shows a number of ellipsoids of various sizes being placed.
    
  \caption{Multiple ellipsoid brushes of different sizes. Due to the sharp edges between an ellipsoid and a plane, small shading artifacts are visible.}


\paragraph{Shapes Using Bezier Curves}
\subparagraph{Exact Method}

To define a smooth curve between interpolation points, we will use Bezier interpolation. Intermediate control points are calculated between each consecutive pair of interpolation points, such that the section of curve between them is a cubic Bezier spline. Calculating the minimum distance to a Bezier curve is best done by minimising the value of a degree 6 polynomial. A general cubic Bezier is a cubic $c\left(t\right), t \in \left[0,1\right]$, and the value of the SDF at point $p$ is the minimum of $\| c\left(t\right) -p\|$. This minimum is found by differentiating $\| c\left(t\right) -p\|^2$, a degree 6 polynomial, to give a polynomial of degree 5.

Since it is impossible to solve a general degree 5 polynomial analytically, we instead use a numerical approach. We will use an existing implementation\cite{kraus_2021} that uses interval approximation to find the first root, followed by polynomial long division to obtain the coefficients of a degree 4 polynomial, and finally computes the 4 remaining roots exactly. Once the minimum distance to the curve has been computed, It is simple to define a shape with a circular cross-section by defining a radius, such that points closer than that radius are considered inside, and points further away are considered outside. Figure \ref{fig:exact_bezier} shows an example of such a shape.

  \caption{A number of Bezier interpolation splines, using the exact SDF.}


We use the numerical derivative as implemented in listing \ref{numerical_gradient}, although this requires solving 5 cubics for every SDF sample point.

\subparagraph{Approximate Method}
To avoid the complex computation that comes with finding the roots of a quintic, a Bezier spline can be approximated by a number of line segments. Each line segment can then be associated with an SDF that is simple to evaluate. For example, figure \ref{fig:spline_approximation} shows a comparison between an approximated spline, and a spline using the exact SDF.

  \caption{Two similar interpolation splines. The nearest spline uses the approximation, whereas the farthest away spline uses the exact SDF. The linear segments of the approximation are more visible where the spline is most curved.}

Using approximations also allows for splines to be used to define more complex shapes, where calculating an exact SDF may be infeasible. Often the shape used for the line segment will result in jagged areas between line segments, when the shape is very curved. To solve this issue, at the ends of the shapes, we only consider the intersection, as demonstrated in figure \ref{fig:road_double}.

Left: Illustration of the union of 2 shapes at an angle, so there is a jagged overlap between them. Right: The same 2 shapes, considering only the intersection between the shapes at the end, giving a smoother appearance.


Figure \ref{fig:bezier_roads} shows a shape generated with this method, using an SDF where each line segment along the spline is represented by a capsule intersected with a half-plane. The SDF for this shape is in listing \ref{road_code}.


Shape generated using splines having a more complex cross-section. Since each cubic curve in the interpolation spline is passed to the shader separately, the smoothing method was not used on the boundary between the curve segments, so some intersections between the shapes are still visible. Implementing this would require significant changes to the editing code, but would result in a smoother shape.


\texttt{road\_distance} is the SDF for part of the shape defined by a single cubic Bezier curve. When an interpolation spline consisting of multiple curves is required, a \texttt{Brush} object is created for each.}]


\subsubsection{Limits of Terrain Modification}

This terrain modification system allows for a wide variety of shapes to be implemented. The efficiency improvements resulting from the use of the octree to prevent iteration over large lists of brushes, and the use of bounding boxes inside the GLSL shader means that a large number of brushes can exist at once, provided they are spread out. However, the number of brushes in the world grows without bound as editing occurs, meaning that slowdown is inevitable, particularly when the number of brushes in a single node becomes high, since this requires more work in the generation shader. This causes a stutter in between frames, when a large amount of geometry need to be regenerated. This can be reduced by limiting the speed of the player so that a large movement in between frames does not happen. There are other ways to address this, which we will discuss in section \ref{section:future_work}. Nevertheless, it is possible to modify the world with many thousands of brushes before significant slowdown occurs.

\section{Graphical User Interface} 

To make editing more intuitive, a basic graphical user interface has been implemented. Text showing the camera position and currently enabled brush is displayed in the bottom left. A list of controls is displayed on the right, and can be hidden if necessary. Controls for the selected brush are shown on the top left. A crosshair is shown in the middle of the screen, to show the user what they are currently pointing at. When a brush is being placed, a preview is shown to the user, to help them understand what modification will be performed. To implement this, the methods \texttt{drawPreview}, \texttt{getDescription}, and \texttt{getDetails} have been added to the \texttt{Action} interface. Listing \ref{action_ui_methods} shows the implementation of these methods for drawing a sphere.

The UI methods for the \texttt{SphereAction} class.

Previews for shapes defined using Bezier splines are shown by approximating the curve with a series of cylinders. Some examples of the user interface are shown in figures \ref{fig:sphere_preview}, \ref{fig:cylinder_preview} and \ref{fig:spline_preview}.

  \caption{Preview of a sphere about to be placed, next to a sphere that has already been placed.}
  
  
  \caption{Preview of a cylinder about to be placed, next to some shapes which have already been placed.}

Preview of an interpolation spline with multiple control points. The use of semi-transparent shapes means that visual artifacts are present when the shapes are drawn in a specific order. This can be solved by drawing the shapes in a specific order. However, since the only purpose of rendering this is to display a preview, this is unneccesary.

\section{Physics}
In many applications it is useful to have collision detection and physics simulation for the terrain. This section explores a method of doing this.
\subsection{Bullet Physics}
To implement physics simulation, the Bullet Physics library~\cite{bullet-physics}, which is a general-purpose CPU based physics library, written in C++. We will use the generic triangle mesh shapes it supports, along with the triangle meshes we have already generated, to implement physics simulation. In particular, these static triangle mesh shapes can be non-convex, making them ideal for our use case.

The library is optimised for speed, and the physics simulation is complex, with multiple different phases used with each timestep. For example, one such phase computes axis-aligned bounding boxes of physics shapes, and returns pairs of objects where these intersect, and a subsequent phase computes the contact points between those objects, using an algorithm chosen based on the types of shape. All of this is encapsulated within a single function, \texttt{stepSimulation}, which takes a time interval, and moves the physics simulation forwards by that amount.

Documentation for the library is automatically generated from source code comments, and as such, is often incomplete and confusing to follow. However, there is a user manual which gives an overview of how some aspects of the library work\cite{coumans_2015}.

\subsection{Creation of Physics Meshes}

The geometry we will use for the physics collision meshes is the same geometry used for rendering, generated by the Transvoxel algorithm. We make use of the \texttt{mapGeometry} function, as described in section \ref{section:raycasting}, to copy the geometry to the CPU memory, so it can be accessed by the library.
Creating a large collision mesh is computationally expensive, and so physics meshes are only constructed on chunks that are generated at the highest level of detail. Figure \ref{fig:meshes1} shows physics meshes being generated in a radius around the camera.


  \caption{Generated physics meshes, shown in red outline.}


Making this restriction on the meshes generated means that there are significantly less physics meshes being generated with each octree update, and also that physics collisions always occur with the same geometry, rather than with geometry at varying levels of detail. If collision with low detail geometry were to occur, finer features in the geometry may be completely ignored. However, this means that collision can only occur where the highest level of detail is used. To solve this, we modify the \texttt{shouldSplit} and \texttt{shouldChop} functions described in section \ref{section:octree}, as shown in listing \ref{phy_lod}.

Snippet from \texttt{shouldSplit} responsible for increasing the level of detail near a set of test objects. All chunks with bounding boxes that intersect the bounding box of a physics shape will be split until the highest detail level is reached. The octree refinement process described in section \ref{section:octree_refinement} ensures that this does not create any places where different levels of detail are adjacent to each other.}]


Figures \ref{fig:meshes2} and \ref{fig:meshes3} show this system in action.


Physics meshes generated for large, far away objects. Meshes are shown in red outline. Due to the high level of detail, the mesh appears to be rendered as a solid block of color.


Chunks generated for a small, far away physics object. There is no place where a very high level of detail and very low level of detail are adjacent to each other, thanks to the refinement algorithm.


\subsection{Player Controller}
To handle player collision, we will use a capsule shape oriented along the y axis. To move the shape, we apply a force in the direction we want to move. The direction of this force is determined by the directional keys being pressed. For example, if the forward key is being pressed, the force will be in the same direction as the x and z components of the look direction of the camera, and the collision shape is pushed in the direction the camera is looking. The other directional keys act similarly. To move upwards, a large upwards force is applied. 
\subsubsection{Editing geometry near the player}
If geometry is edited near the player, it is possible for the collision shape to become stuck in the collision meshes, or even pass through it entirely, resulting in incorrect collisions. To prevent this from happening, there is the option of a simple camera mode, with no collision detection, and terrain editing can be restricted to only this mode. In this case, the collision shape is moved to the new position of the camera when the mode is switched again.
\subsection{Multithreading}

Even when meshes are only generated for chunks at the highest level of detail, mesh generation for a large chunk of geometry still takes long enough to cause a noticable slowdown. This is because a data structure is created internally for each mesh collision object.

So physics meshes can be generated whilst maintaining an interactive framerate, they are generated on a separate thread. All of the information about the collision mesh for a chunk is stored in a \texttt{ChunkMesh} object. There are numerous ways in which race conditions can occur as a result of this multithreading, for example:

  A chunk is deleted, whilst a mesh computation that relies on the geometry within is still ongoing on another thread, causing deallocated memory to be read.
  A generated physics mesh is added to the simulation by a secondary thread whilst the main thread is performing other calculations to simulate the world, causing errors within the library. This occurs particularly when library functions are iterating over collections of objects already in the simulation, since modifying such collections during iteration can cause unpredictable behaviour. Due to the complexity of the library, it is impractical to anticipate all of the situations where this could occur, and hence we will treat the library function \texttt{stepSimulation} as a black box, only modifying the objects inside the physics simulation within the same thread as this function.
  
To ensure no race conditions of these types occur, the state of a \texttt{ChunkMesh} object is stored in an atomic variable, and carefully maintained throughout its lifetime. Each method that may cause a race condition related to a \texttt{ChunkMesh} object performs an atomic compare-and-swap operation on this variable, to ensure the state remains consistent throughout. There are 7 possible states of a \texttt{ChunkMesh}, and the generation process can be described in terms of this state:

  \texttt{CHUNKMESH\_INITIALIZED}: The initial state of a \texttt{ChunkMesh}. On the main thread, the geometry is copied to the CPU, and the object is added to a thread-safe queue \texttt{multiQueue}, which is read by the physics generation threads.
  \texttt{CHUNKMESH\_GENERATING}: A physics generation thread removes a \texttt{ChunkMesh} object from \texttt{multiQueue}, changes its state from \texttt{CHUNKMESH\_INITIALIZED} to \texttt{CHUNKMESH\_GENERATING}, and begins executing the expensive library functions responsible for creating the physics object.
  \texttt{CHUNKMESH\_FUTURE\_DELETE}: The main thread has attempted to delete the chunk this \texttt{ChunkMesh} belongs to, whilst a physics thread was still working on it. The main thread changes its state from \texttt{CHUNKMESH\_GENERATING} to \texttt{CHUNKMESH\_FUTURE\_DELETE}
  \texttt{CHUNKMESH\_GENERATED}: A physics thread has finished the computation for the \texttt{ChunkMesh}, and has changed the state from \texttt{CHUNKMESH\_GENERATING} to \texttt{CHUNKMESH\_GENERATED}. The \texttt{ChunkMesh} object is added to a thread-safe queue \texttt{singleQueue} which is checked regularly by the main thread.
  \texttt{CHUNKMESH\_INWORLD}: The main thread removes a \texttt{ChunkMesh} object from \texttt{singleQueue}, adds it to the physics simulation, and changes the state from \texttt{CHUNKMESH\_GENERATED} to \texttt{CHUNKMESH\_INWORLD}.
  \texttt{CHUNKMESH\_REMOVING}: A \texttt{ChunkMesh} which was moved to state \texttt{CHUNKMESH\_FUTURE\_DELETE} is moved to \texttt{CHUNKMESH\_REMOVING} instead of \texttt{CHUNKMESH\_GENERATED} when the physics computation finishes. It is also added to \texttt{singleQueue}
  \texttt{CHUNKMESH\_REMOVED}: A \texttt{ChunkMesh} is removed from \texttt{singleQueue} by the main thread. If it is in the state \texttt{CHUNKMESH\_INITIALIZED}, then it has not been removed from \texttt{multiQueue} yet, and the expensive computation has not started. The state is changed to \texttt{CHUNKMESH\_REMOVED}, so the computation does not start. If it is in the state \texttt{CHUNKMESH\_INWORLD}, then the mesh has been created, and is currently in the world. The \texttt{ChunkMesh} is removed from the physics simulation and deleted. If it is in the state \texttt{CHUNKMESH\_REMOVING}, then the physics computation has completed, but the mesh is not in the world. The \texttt{ChunkMesh} is deleted.

  \caption{States of a physics mesh}
  

\subsection{SDF-Based Physics}
Since all of the geometry is generated using SDFs, there is a possibility of using an SDF for physics simulation, rather than the generated mesh, which is an approximation. In fact, determining whether collision occurs between a sphere and a shape represented by an \textit{exact} SDF is very simple and efficient, requiring only one evaluation of the SDF.

The situation is more complicated with approximate SDFs, since the value of the SDF is no longer guaranteed to be the exact distance from the surface, and so there is no guarantee that moving even a small amount in some direction will not lead to a collision, making this approach ineffective. Figure \ref{fig:approx_collision} shows a 2D example of this.

A circle with radius $0.5$ near an approximate SDF, where the distance is not exact. Here the dashed line is the contour line of the approximate SDF $f\left(x,y\right) = y - \left(1 - \frac{x^2}{3}\right)$ where the value is $0.5$. If this were an exact SDF, then the shapes would only just touch, however they are intersecting.

Collision between an SDF and a different shape is more complicated, even if the SDF is exact. Since the distance between a surface and a shape is different depending on the orientation of the shape, and evaluation of an SDF gives no information about direction to the nearest point on the surface, such a system would be inaccurate. This method could be used with an approximate SDF which provides a lower bound of the distance to the surface, along with a spherical bounding volume for physics shapes, to perform culling on objects to determine when it is impossible for them to intersect. However, we will not explore this here, choosing instead to remain with the library implementation. 

\section{Shading}

A good way to improve the appearance of the generated terrain is to apply some shading. We make use of a modified version of Phong lighting, with 2 light sources. We use a far away light source to represent the sun, with both diffuse and specular reflection. We also use a light source which is positioned directly above the camera, that only contributes a diffuse component. This gives the appearance that nearby geometry is lighter than geometry that is further away, and excluding the specular component from the player light source prevents everything from appearing shiny.

Part of the fragment shader implementing this lighting model.

We make use of a customized fragment shader, defining the color of the terrain based on its position and normal using procedural texturing. This has a benefit over using a tiled image, which shows a repeating pattern over a large area. Listing \ref{procedural_shading} shows some procedural texturing using noise to interpolate between different shades of a color, rather than using a flat color. It appears as grass on horizontal surfaces, and rock on vertical surfaces.

The variable \texttt{grassAmount} determines how much grass is visible at a given point. The noise used to define the rock color has been stretched in the x and z directions. The result is a color that changes more quickly as the y coordinate changes.

Figure \ref{fig:procedural_shading_shapes} shows the shading produced by this algorithm.

Plane, cylinder and sphere, textured using this procedural texturing method.
  

When these techniques are applied alongside a well-chosen noise-based terrain function, the result is a visually appealing landscape.

Mountainous landscape generated using noise, and textured with procedural texturing.

\section{Changes in the Implementation}
The code has been iteratively improved over the course of the project. This section briefly explores some of the improvements implemented during development.

\subsection{Storage of Transvoxel Sample Values}

Each SDF sample value calculated in the first shader stage is stored in a flat buffer, to be retrieved by the later stages. Values are indexed into this buffer with the function \texttt{getArrID} that takes the position of the sample relative to the chunk, and returns an index. When the sample points are arranged in a grid, this is relatively simple, however things become more complicated for the sample points in the Transvoxel algorithm, since there are sample points that are midway between the grid cell vertices when transition cells are generated. A simple solution was to double the size of the array in each dimension, so that sample points halfway between grid cells fit in as though the grid size was changed, however this leads to a very sparse buffer that is far larger than it needs to be. A more space-efficient solution stores the sample points not on the faces of the chunk as a cuboid. Then, each face of the chunk is stored at the end of the buffer, so that additional sample points on the face can fit. This results in much less wasted space.

The more efficient \texttt{getArrID} function.

\subsection{Storage of Editing Brushes}
The first iteration of the editing algorithm stored all brushes for the entire world in one single array, making it simple to add brushes, but meaning that the entire array of brushes had to be iterated through for every chunk, which was prohibitively slow for a large number of brushes, even when individual chunks had a small amount of brushes within them. 

Using the pre-existing octree to store lists of brushes for each chunk, as described in section \ref{section:modification_implementation}, removed the need to do this iteration, at the expense of having to iterate over the octree to add a brush.

\subsection{Bounding Boxes and Grid Cells}
As described in section \ref{section:modification_implementation}, an SDF is only evaluated if the grid cell being worked on intersects its bounding box. A previous iteration only considered whether the sample point was within this bounding box, which resulted in incorrect vertex interpolation in grid cells partially inside the SDF bounding box. This was corrected by extending the bounding box check to include cases where the grid cell intersects the bounding box, even if the sample point does not.

Different iterations of the SDF bounding box check.

\section{Conclusion}
\subsection{Reflection}
In this project we have achieved the goal of generating a large area of procedural terrain that can be interacted with in real-time using the Transvoxel algorithm. We showed that parallelising the algorithm on the GPU gives a massive speedup compared to a CPU implementation.

We applied techniques seen in the Geometric Modelling course in interesting ways, using an octree to partition space into regions with different levels of detail, and using interpolation splines as a part of an SDF defining more complex shapes. 
We have also used techniques seen in the Computer Graphics course for handling geometry and rendering 3D images, and from the Concurrent Algorithms and Data Structures course, such as using atomic variables and the compare-and-swap operation to protect against race conditions, in section \ref{section:multithreading}.

At the start of this project, I had some experience working with C++ and the libraries responsible for interacting with OpenGL. The choice of OpenGL as an API was a straightforward one, since it is well-established, and widely supported on modern hardware and operating systems. C++ as a language is also widely used, and compiled code can be very efficient compared to other languages. However, developing in C++ is more challenging than other, higher level languages, with added complexity such as memory management to consider. Developing on Windows, configuring a compiler with libraries introduced throughout development was a source of particular frustration, since each library must be compiled and linked manually. This could be avoided in language that had a more standardised way of including libraries. It would be interesting to implement a similar project in a language such as Python, where bindings for both OpenGL and Bullet Physics exist, comparing the execution speed to the equivalent C++ program.

I particularly enjoyed creating SDFs to represent terrain, and it was satisfying to be able to define a shape using an equation and immediately see it rendered. 

The final implementation contains XXXX lines of code.

\subsection{Future Work}
\subsection{Octree Refinement Improvements}
Currently, only octree leaves that contain physics objects are maintained by the \texttt{shouldChop} function, and all of the leaves that were created by the previous iteration of the refinement algorithm are flagged. Although the flagging means that geometry is not being regenerated every time, this still results in a large amount of unneccesary iteration over the octree as nodes are repeatedly flagged, and then unflagged again.
\subsubsection{Bounding the main SDF}
No equivalent to a bounding box has been implemented for the main SDF. For functions defined by noise, this becomes challenging, since there could be large regions within the area affected by the SDF, which do not contain any of the surface. Implementing this would enable improvements similar to those in \ref{section:modification_implementation}, preventing SDF computation at a point that is not near the surface. If every part of the SDF was bounded, it would be possible to completely eliminate computation of the SDF in chunks that were outside of these bounds.
\subsubsection{Additional Multithreading}
Currently, any geometry generated as a result of an octree update is generated before the next frame is drawn, causing stuttering when a lot of editing is performed, as seen in section \ref{edit_limits}, or when the camera moves very fast. Performing geometry generation and rendering on separate threads would allow for techniques that prevent this slowdown, such as artificially limiting the rate at which new chunks are generated. This would reduce the speed at which the octree can be updated, but would improve the framerate.
\subsubsection{Blends}
Using a blend function in between SDFs would reduce the number of places where sharp corners appear in the SDF. Care would have to be taken that the blend function does not result in geometry being modified outside of the bounding box of the shape being added, or this would result in incorrect generation.
\subsubsection{Terrain Materials}
Alongside a distance and normal function, a material function could also be defined, describing the type of geometry at each point, for example distinguishing between grass and rock. Grid cells could then be shaded by sampling the material function at their vertices. Care would have to be taken when shading cells having different materials at each vertex.
